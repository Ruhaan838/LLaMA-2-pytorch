<div align="center">

# LLaMA-2 - Let's Reproduce LLaMA from Scratch

<div style="display:flex; justify-content:center; gap: 20px;">

[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-FFD21E?logo=huggingface&logoColor=000)](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)

[![arXiv](https://img.shields.io/badge/arXiv-LLaMA-B31B1B?logo=arXiv&logoColor=white)](https://arxiv.org/abs/2302.13971)


</div>

</div>

## Introduction

LLaMA (Large Language Model Meta AI) is an open-source language model it's has great benchmarks. This repository I will try to reproduce the LLaMA model from scrach with **training** and **inference**.

## Acknowledgements
- [Original Paper](https://arxiv.org/abs/2302.13971)